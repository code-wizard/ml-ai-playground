{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import exp, tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(betas, x):\n",
    "    b0 = betas[0]\n",
    "    sumOfX=0\n",
    "    for index,i in enumerate(x):\n",
    "        sumOfX = sumOfX + betas[index + 1] * i\n",
    "    log_ods = np.exp(b0 + sumOfX)\n",
    "    logis = log_ods / (1 +  log_ods)\n",
    "    return logis\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7037876330368581"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic([-0.51, 0.46, -0.004], [3,1.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward - Naural Network\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(arr):\n",
    "    return 1 / (1 + np.exp(-arr))\n",
    "\n",
    "def run(inputs, hidden_weights, output_weights, bias=1, no_layers=1):\n",
    "    for i in range(no_layers):\n",
    "        for w in hidden_weights:\n",
    "            layer = relu(np.dot(inputs.flatten(),w) + bias)\n",
    "            inputs = layer\n",
    "    return sigmoid(layer.dot(output_weights.flatten()) + bias)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9399133498259924"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(np.array([[1,0]]).reshape(1,2), [np.array([[0.5,1],[-0.5, -1]]), ], np.array([[0.1, 0.8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 1.  ]\n",
      "[-0.5  0.5]\n"
     ]
    }
   ],
   "source": [
    "np.array([[0.25,-0.5],[1,0.5]])\n",
    "# np.array([[0.25,1],[-0.5, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard RNN \n",
    "# a(t) = b + Wh(t-1) + Ux(t)\n",
    "# h(t) = tanh(a(t))\n",
    "#o(t) = c + Vh(t)\n",
    "# y(t) = softmax(o(t))\n",
    "# t1 = 3 and t2=0.5\n",
    "# Wx =0.25 , Wh=0.5, Wo = 0.1\n",
    "#bias = 0\n",
    "\n",
    "def do_step(bias, w1, w2, inputs, ouput_weight):\n",
    "    t = 0\n",
    "    for inp in inputs:\n",
    "        lin = bias +( w1 * t ) + (w2 * inp)\n",
    "        step = tanh(lin)\n",
    "        t = step\n",
    "    output = ouput_weight * step\n",
    "    y = sigmoid(output)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5103929065166696"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_step(0, 0.5, 0.25, [3,0.5], 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv4",
   "language": "python",
   "name": "opencv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
